{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIGtor: Supplementary Synthetic Image Generation for Object Detection and Segmentation Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "A significant challenge in deep learning tasks, particularly in classification, detection, and segmentation, is the requirement for extensive, well-balanced training datasets. This challenge is especially pronounced in detection and segmentation tasks, where creating large datasets is often a time-consuming, tedious, and error-prone process. Consequently, data augmentation has become essential in training deep learning models, enabling the expansion of small datasets through various morphological or geometrical transformations, applied either on-the-fly during the training process or offline.\n",
    "\n",
    "This notebook demonstrates a method for artificially generating a theoretically unlimited number of supplementary datasets for object detection or segmentation from an existing dataset, regardless of its initial size. The algorithm presented here employs a simple yet robust copy-paste augmentation technique that effectively handles object overlap, dynamic placement on background images, and supports both object-level and image-wide augmentations. The generated synthetic images will include instance segmentation masks and tightly fitting bounding boxes. We refer to this system as SIGtor, which stands for Synthetic-Image-Generator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Introduction\n",
    "\n",
    "A significant challenge in deep learning tasks, particularly in classification, detection, and segmentation, is the requirement for extensive, well-balanced training datasets. This challenge is especially pronounced in detection and segmentation tasks, where creating large datasets is often a time-consuming, tedious, and error-prone process. Consequently, data augmentation has become essential in training deep learning models, enabling the expansion of small datasets through various morphological or geometrical transformations, applied either on-the-fly during the training process or offline.\n",
    "\n",
    "This notebook demonstrates a method for artificially generating a theoretically unlimited number of supplementary datasets for object detection or segmentation from an existing dataset, regardless of its initial size. The algorithm presented here employs a simple yet robust copy-paste augmentation technique that effectively handles object overlap, dynamic placement on background images, and supports both object-level and image-wide augmentations. The generated synthetic images will include instance segmentation masks and tightly fitting bounding boxes. We refer to this system as SIGtor, which stands for Synthetic-Image-Generator.\n",
    "\n",
    "## Assumptions\n",
    "\n",
    "<div style=\"margin-bottom: 20px;\">\n",
    "    <strong>Dataset Availability</strong><br>\n",
    "    You have a dataset that you intend to extend using SIGtor. <strong>Note</strong>: SIGtor is an offline dataset generator, not an augmentation technique for use during the training of deep learning models. The generated images, with or without the original images, can be used to train a model.\n",
    "</div>\n",
    "\n",
    "<div style=\"margin-bottom: 20px;\">\n",
    "    <strong>Dataset Annotation</strong><br>\n",
    "    Your dataset should be annotated in YOLO format, with bounding boxes specified as follows:\n",
    "</div>\n",
    "\n",
    "<div style=\"border: 2px solid #4CAF50; padding: 10px; background-color: #f9f9f9; font-family: monospace; font-size: 14px; margin-bottom: 20px;\">\n",
    "    ./Datasets/Source/Images/image1.jpg $x_1$,$y_1$,$x_2$,$y_2$,$A$ $x_1$,$y_1$,$x_2$,$y_2$,$B$ $x_1$,$y_1$,$x_2$,$y_2$,$C$ $x_1$,$y_1$,$x_2$,$y_2$,$D$\n",
    "</div>\n",
    "\n",
    "    \n",
    "For this demo, I will use Pascal VOC or COCO Object Detection and Instance Segmentation Masks, downloaded from Kaggle or the COCO dataset site. Tools for converting either the Pascal VOC or COCO dataset into YOLO format can be found in the `tools` folder of this project.\n",
    "\n",
    "While the project folder structure is flexible, it is recommended to organize your files as shown below:\n",
    "\n",
    "<div style=\"border: 2px solid #007BFF; padding: 15px; background-color: #f0f8ff; font-size: 14px; border-radius: 5px; font-family: monospace; margin-bottom: 20px;\">\n",
    "SIGtor/<br>\n",
    "├── Dataset/<br>\n",
    "│   ├── Source/<br>\n",
    "│   │   ├── images/<br>\n",
    "│   │   ├── masks/<br>\n",
    "│   │   └── source_annotations.txt<br>\n",
    "│   ├── Background/<br>\n",
    "│   └── Sigtored/<br>\n",
    "│   │   ├── augmented_images/<br>\n",
    "│   │   ├── augmented_masks/<br>\n",
    "│   │   └── sigtored_annotations.txt<br>\n",
    "├── tools/<br>\n",
    "├── augmentations.py<br>\n",
    "├── config.py<br>\n",
    "├── data_processing.py<br>\n",
    "├── data_utils.py<br>\n",
    "├── demo.ipynb<br>\n",
    "├── expand_annotations.py<br>\n",
    "├── file_operations.py<br>\n",
    "├── image_compositions.py<br>\n",
    "├── image_processing.py<br>\n",
    "├── index_generator.py<br>\n",
    "├── License.txt<br>\n",
    "├── requirements.py<br>\n",
    "├── readme.md<br>\n",
    "├── sigtor.py<br>\n",
    "├── test_sigtor.py<br>\n",
    "└── utils.py\n",
    "</div>\n",
    "\n",
    "<div style=\"margin-bottom: 20px;\">\n",
    "    <strong>Background Images</strong><br>\n",
    "    Download some images from the internet to be used as background images and place them in the `Background` folder as shown above. While not mandatory, using realistic background images instead of plain backgrounds can enhance the quality of the generated synthetic images. You can automate the download process using tools such as <a href=\"https://github.com/hardikvasa/google-images-download\">this one</a> or <a href=\"https://levelup.gitconnected.com/how-to-download-google-images-using-python-2021-82e69c637d59\">this one</a>. Once downloaded, manually remove any background images that contain objects from your dataset classes, as including unannotated objects could confuse your model's loss functions.\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## SIGtor: The Steps\n",
    "\n",
    "The synthetic image generation process involves two main steps:\n",
    "\n",
    "<ul>\n",
    "<div style=\"margin-bottom: 20px;\">\n",
    "<li><strong>Step 1: Expand the Source Annotation.</strong></li>\n",
    "Consider the example below where an image contains four annotated objects (A, B, C, and D):\n",
    "\n",
    "<center><img src=\"./misc/example1.png\" width=\"500\" /></center>\n",
    "\n",
    "The annotations might look like this:\n",
    "\n",
    "<div style=\"border: 2px solid #4CAF50; padding: 10px; background-color: #f9f9f9; font-family: monospace; font-size: 14px;\">\n",
    "./Datasets/Source/Images/image1.jpg $x_1$,$y_1$,$x_2$,$y_2$,$A$ $x_1$,$y_1$,$x_2$,$y_2$,$B$ $x_1$,$y_1$,$x_2$,$y_2$,$C$ $x_1$,$y_1$,$x_2$,$y_2$,$D$\n",
    "</div>\n",
    "\n",
    "<i>(Note: A, B, C, and D represent the integer indices of the object classes, and the coordinates will differ based on the actual positions of the objects.)</i>\n",
    "\n",
    "The `expand_annotation.py` script processes these annotations by automatically calculating the Intersection over Union (IoU) for each pair of objects. It then re-annotates the lines based on the following rules:\n",
    "\n",
    "<div style=\"border: 2px solid #007BFF; padding: 15px; background-color: #f0f8ff; font-size: 14px; border-radius: 5px;\">\n",
    "    <ul style=\"margin-left: 20px;\">\n",
    "        <li><strong>Non-overlapping objects:</strong> Each non-overlapping object is assigned its own annotation line, as with object <b>D</b>.</li>\n",
    "        <li><strong>Completely embedded objects:</strong> Objects that are entirely within the bounds of a larger object (e.g., <b>B</b> within <b>A</b>) also receive their own annotation line.</li>\n",
    "        <li><strong>Overlapping objects:</strong> Larger objects that partially overlap with others (e.g., the relationship between <b>A</b> and <b>C</b>) or contain smaller objects within their coordinates (e.g., the relationship between <b>A</b> and <b>B</b>) are annotated together.</li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "After expansion, the original annotation line will be divided into at least three lines:\n",
    "\n",
    "<div style=\"border: 2px solid #4CAF50; padding: 10px; background-color: #f9f9f9; font-family: monospace; font-size: 14px;\">\n",
    "./Datasets/Source/Images/image1.jpg $x_1$,$y_1$,$x_2$,$y_2$,$D$<br>    \n",
    "./Datasets/Source/Images/image1.jpg $x_1$,$y_1$,$x_2$,$y_2$,$B$<br>\n",
    "./Datasets/Source/Images/image1.jpg $x_1$,$y_1$,$x_2$,$y_2$,$A$ $x_1$,$y_1$,$x_2$,$y_2$,$B$ $x_1$,$y_1$,$x_2$,$y_2$,$C$\n",
    "</div>\n",
    "\n",
    "To complete this step, simply run the `expand_annotation.py` script with the appropriate command-line arguments, or without arguments if you have already configured the `sig_argument.txt` file with the correct inputs.\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "<div style=\"margin-top: 20px;\">\n",
    "<li><strong>Step 2: Generate the Artificial Images.</strong></li>\n",
    "\n",
    "The next step involves generating synthetic images. The details of this process are illustrated in the GIF below:\n",
    "\n",
    "<center><img src=\"./misc/SIGtor.gif\" width=\"900\"></center>\n",
    "\n",
    "Sample SIGtored images and masks can be found in the project's `Datasets/SIGtored` folder. To generate new artificial images, clone this project and run `synthetic_image_generator.py` as is. If you want to work with your own dataset or other public datasets like COCO and VOC for your next object detection or segmentation training, edit the `sig_argument.txt` file accordingly and follow the two steps described above.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "This experimental project has demonstrated the effectiveness of using synthetic image generation to improve the performance of object detection models. By applying this approach, I was able to enhance the accuracy of YOLOv3, as well as my own versions, MultiGridDet and DenseYOLO (a lighter implementation of YOLOv2), gaining a few extra percentage points in accuracy compared to the original YOLO models. This experience has reinforced my belief that copy-paste augmentation is a powerful tool for training deep learning models.\n",
    "\n",
    "However, there are important considerations to keep in mind:\n",
    "\n",
    "<ol>\n",
    "<li><strong>Class Balance:</strong> It is crucial to avoid over-representing certain object classes. Although I have incorporated mechanisms to under-sample over-represented classes like \"Person\" and \"Car\" to mitigate imbalance, users are encouraged to experiment with these features to suit their specific needs.</li>\n",
    "\n",
    "<li><strong>Dataset Variability:</strong> Ensuring that the training dataset is not overly repetitive is vital to prevent overfitting. A diverse dataset will lead to more robust model performance.</li>\n",
    "</ol>\n",
    "\n",
    "Finally, I have not observed any significant negative impact on model performance due to potential artifacts from the SIGtored objects or the lack of perfect seamlessness in the pasted objects. While training the model for extended periods might increase the likelihood of the network recognizing these artifacts, this is generally true for any model trained extensively on a fixed dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
